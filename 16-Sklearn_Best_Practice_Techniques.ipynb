{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/twMr7/Python-Machine-Learning/blob/master/16-Sklearn_Best_Practice_Techniques.ipynb)\n",
    "\n",
    "# 16. Sklearn - 實用技巧\n",
    "\n",
    "前幾章的內容裡介紹了建立機器學習模型的基本流程，以及必要的確效驗證步驟。 實務上，建立有效學習模型之前還會有一些不同的問題要解決，例如接下來會提到的交叉驗證及模型超參數選取。 在加入越來越多處理的程式碼後，整個建立模型的步驟也會慢慢變得複雜、難以組織。 這章要介紹 Scikit-learn 所提供的一些實用工具，可以用來簡化這些問題的處理。\n",
    "\n",
    "+ [**16.1 Pipeline**](#pipeline)\n",
    "+ [**16.2 交叉驗證 Cross-Validation**](#cross-validation)\n",
    "+ [**參考資料**](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab 環境\n",
    "\n",
    "在 Google Colab 的環境下，請執行以下程式碼。（詳細說明請參閱 14 章）\n",
    "```\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "建立 `dataset` 目錄的連結，記得修改成適合的路徑。\n",
    "```\n",
    "!ln -svf 'drive/My Drive/Lecture/Python Machine Learning/dataset' dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 載入 House Prices 資料集\n",
    "train_data = './dataset/HousePrices/train.csv'\n",
    "X = pd.read_csv(train_data, index_col='Id')\n",
    "\n",
    "# 目標欄位有漏失標籤的資料列優先丟掉\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "# 把 X, Y 分開\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# 不同特徵群組\n",
    "category_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "low_card_cols = [col for col in category_cols if X[col].nunique() < 6]\n",
    "high_card_cols = list(set(category_cols) - set(low_card_cols))\n",
    "numerical_cols = list(set(X.columns) - set(category_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "\n",
    "## 16.1 Pipeline\n",
    "\n",
    "`Pipeline` 的設計是用來對整個工作流程簡化。 概念上的簡化處理手法就是\n",
    "1. 先把個別步驟的方法分別定義好。\n",
    "2. 將負責處理每個步驟的物件，按照順序放進流程清單，學習模型物件放最後。\n",
    "3. 對資料集都套用相同的（前）處理流程。\n",
    "\n",
    "使用 `Pipeline` 的明顯好處是： 比較乾淨的程式碼、流程清楚明確易於維護、有更多的模型確效工具可使用。 Scikit-learn 提供來簡化工作流程的類別有：\n",
    "+ [**`sklearn.pipeline.Pipeline(steps)`**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "    - **steps**： 是工作流程的清單，照工作順序放 (*name*, *transform*) 的 tuple 的清單，最後一個一定要是 estimator。\n",
    "+ [**`sklearn.pipeline.ColumnTransformer(transformers, remainder, n_jobs)`**](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) - 用來針對不同欄位分別套用不同處理，最後會串接各特徵欄位的處理結果。\n",
    "    - **transformers**： 可以是指定 (*name*, *transformer*, *columns*) 的 tuple 清單，也可以是 *estimator* 或字串 'passthrough'、'drop' 之一。\n",
    "    - **remainder**： 指定剩下的欄位如何處理，可以是 *estimator* 或字串 'passthrough'、'drop' 之一。\n",
    "    - **n_jobs**： 指定使用幾個處理器核心平行運算\n",
    "\n",
    "Note: **`Transformer`** 指的是有實作 `fit()` 及 `transform()` 方法的類別； **`Estimator`** 指的是任何有實作 `transfrom()` 方法的類別。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# 數值欄位前處理\n",
    "numerical_transformer1 = SimpleImputer(strategy='constant')\n",
    "# nominal 類別前處理\n",
    "nominal_transformer1 = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "# ordinal 類別前處理\n",
    "# Note: OrdinalEncoder 沒有提供忽略未知類別的參數\n",
    "ordinal_transformer1 = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant')),\n",
    "        ('onehot', OrdinalEncoder(categories='auto'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § 使用 `ColumnTransformer` 分別處理不同欄位\n",
    "\n",
    "數值欄位、ordinal 和 nominal 類別數據的前處理分別定義，然後放在 `ColumnTransformer` 裡並指定對應的處理欄位，但 `OrdinalEncoder` 需要另外特別處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 把針對不同欄位的處理綁在一起\n",
    "preprocessor1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_transformer1, numerical_cols),\n",
    "        #('ordinal', ordinal_transformer1, high_card_cols),\n",
    "        ('nominal', nominal_transformer1, low_card_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § 使用 Pipeline 學習及驗證\n",
    "\n",
    "最後我們將前處理與模型綁在一個 Pipeline 上。 與一般的學習模型一樣，最終包含前處理及學習模型的 Pipeline 有 `fit()` 及 `predict()` 方法，訓練及確效驗證就改成使用 Pipeline 的方法。 可以注意到，不需要再分別對 training set 和 validation set 各套一次相同的處理程式碼， Pipeline 會在訓練或預測之前負責自動處理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "策略 1 MAE: 17779.828047945204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 將前處理及學習模型定義為制式的 pipeline 工作流程\n",
    "model1 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "pipe1 = Pipeline(steps=[('preprocessor1', preprocessor1), ('model1', model1)])\n",
    "\n",
    "# 相同的工作流程套用到訓練集的學習，以及驗證集的預測\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "pipe1.fit(X_train, y_train)\n",
    "predicts1 = pipe1.predict(X_valid)\n",
    "print('策略 1 MAE:', mean_absolute_error(y_valid, predicts1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § 細緻一點的處理手法\n",
    "\n",
    "由於 `OrdinalEncoder` 沒有提供忽略未知類別的參數，上一個範例的 preprocessor1 裡若加入 ordinal_transformer，將會導致在 validation set 裡沒看過的類別轉碼失敗。 使用 `Pipeline` 遇到這樣的狀況時，就只好自己寫一個相容的前處理類別，或是另外把前處理獨立在 train-test 分割前作。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 避免改到原始的資料，複製一份 X\n",
    "X2 = X.copy()\n",
    "# ordinal 欄位編碼獨立處理，不放在 pipe 裡\n",
    "X2[high_card_cols] = X2[high_card_cols].fillna(value='NA') \n",
    "ordinal_encoder = OrdinalEncoder(categories='auto')\n",
    "X2[high_card_cols] = ordinal_encoder.fit_transform(X2[high_card_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先前的經驗知道，有 NaN 的數值欄位丟掉效果比較好\n",
    "num_cols_with_na = [col for col in numerical_cols if X2[col].isna().any()]\n",
    "num_cols_no_na = list(set(numerical_cols) - set(num_cols_with_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數值欄位前處理\n",
    "numerical_transformer2 = SimpleImputer(strategy='constant')\n",
    "# nominal 類別前處理\n",
    "nominal_transformer2 = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把針對不同欄位的處理綁在一起\n",
    "preprocessor2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('num_with_na', 'drop', num_cols_with_na),\n",
    "        ('num_no_na', numerical_transformer2, num_cols_no_na),\n",
    "        ('ordinal', 'passthrough', high_card_cols),\n",
    "        ('nominal', nominal_transformer2, low_card_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "策略 2 MAE: 16894.790547945206\n"
     ]
    }
   ],
   "source": [
    "# 將前處理及學習模型定義為制式的 pipeline 工作流程\n",
    "model2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "pipe2 = Pipeline(steps=[('preprocessor2', preprocessor2), ('model2', model2)])\n",
    "\n",
    "# 相同的工作流程套用到訓練集的學習，以及驗證集的預測\n",
    "X2_train, X2_valid, y_train, y_valid = train_test_split(X2, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "pipe2.fit(X2_train, y_train)\n",
    "predicts2 = pipe2.predict(X2_valid)\n",
    "print('策略 2 MAE:', mean_absolute_error(y_valid, predicts2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cross-validation\"></a>\n",
    "\n",
    "## 16.2 交叉驗證 Cross-Validation\n",
    "\n",
    "在之前的確效驗證範例中，我們為了儘可能模擬真實世界的新資料，保留了一小部分（holdout）的子資料集與訓練過程隔離。 範例中使用 `train_test_split()` 的工具函式來幫忙，但其實隱藏了一些還沒被提出來討論的問題：\n",
    "+ 要保留那一小部分作確效驗證才有代表性？\n",
    "+ 要保留多大的驗證集？ 還是保留多少的比例？\n",
    "\n",
    "光是切割就有很多可以討論的細節，但簡單直覺的答案就是： 最好是全部資料都用來訓練和驗證。 這個簡單的概念是可以有折衷方式完成的，把訓練集拆成 k 個小段（k-fold），每次都只保留其中某一段作驗證，其餘的作訓練，全部小段都同樣輪流作一次，然後把 k 次的結果作平均。 這樣就所有的資料都有訓練過也驗證過，這種交叉驗證的手法我們稱為 **k-Fold Cross-Validation**。\n",
    "\n",
    "![5-Fold Cross-Validation](./image/kfold_cross_validation.png)\n",
    "\n",
    "上圖（[圖示來源](https://www.kaggle.com/learn/intermediate-machine-learning)）將資料切割為五段，每一段包含所有資料集的其中 20%，這樣我們稱為 5-fold。 因為沒有浪費任何資料，這樣的交叉驗證方式可以更精準的評估學習模型的效能。 缺點是 k 次的交叉驗證要花比較久的時間運算，所以如果是如百萬筆等級的大型資料集，隨機抽樣 1% 都還有個一萬筆，這樣就可以不需要 k-fold。 至於要選擇幾個 k 的 fold，沒有一定的準則，通常是觀察拿來訓練的數量是否足夠大。 一般的選擇會是 train-test 80-20 的比例，若是訓練集非常小的話可以採取 leave-one-out（共 n 筆作 n-fold）的特殊作法。 \n",
    "\n",
    "所以整體而言，機器學習資料集的使用方式常見如下圖（[圖示來源](https://scikit-learn.org/stable/modules/cross_validation.html)）的分配方式。\n",
    "全部資料會先分割成 *Training set* 與 *Test set*，只拿 *Training set* 來作訓練及 k-fold 交叉驗證，*Test set* 完全不參與模型的訓練及交叉驗證，只有在最後模型訓練結束後用來預測評估結果。\n",
    "\n",
    "![k-Fold Cross-Validation with Test](./image/kfold_cross_validation_with_test.png)\n",
    "\n",
    "Scikit-learn 將交叉驗證的類別放在 `model_selection` 模組中，以下範例會介紹常用的 `KFold` 及 `cross_validate` 的用法。\n",
    "+ [**`sklearn.model_selection.KFold(n_splits, shuffle)`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "+ [**`sklearn.model_selection.StratifiedKFold(n_splits, shuffle)`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) - 適合分類問題，分割會保持每種類別的數量比例。\n",
    "+ [**`sklearn.model_selection.cross_validate(estimator, X, y, scoring, cv, n_jobs, return_train_score)`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "+ [**`sklearn.model_selection.cross_val_score(estimator, X, y, scoring, cv, n_jobs)`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) - 適合只需要交叉驗證的 score 時使用。\n",
    "\n",
    "Note: 由於 k-Fold 交叉驗證需要花比較久的時間，物件方法中若有支援平行運算的 **n_jobs** 參數，請儘可能設定使用所有的 CPU 核心。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備新的 Cross-Validation Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "cv_X = X.copy()\n",
    "# ordinal 欄位編碼獨立處理，不放在 pipe 裡\n",
    "cv_X[high_card_cols] = cv_X[high_card_cols].fillna(value='NA') \n",
    "ordinal_encoder = OrdinalEncoder(categories='auto')\n",
    "cv_X[high_card_cols] = ordinal_encoder.fit_transform(cv_X[high_card_cols])\n",
    "\n",
    "# 先前的經驗知道，有 NaN 的數值欄位丟掉效果比較好\n",
    "num_cols_with_na = [col for col in numerical_cols if cv_X[col].isna().any()]\n",
    "num_cols_no_na = list(set(numerical_cols) - set(num_cols_with_na))\n",
    "\n",
    "# 數值欄位前處理\n",
    "cv_numerical_transformer = SimpleImputer(strategy='constant')\n",
    "# nominal 類別前處理\n",
    "cv_nominal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "# 把針對不同欄位的處理綁在一起\n",
    "cv_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_no_na', cv_numerical_transformer, num_cols_no_na),\n",
    "        ('ordinal', 'passthrough', high_card_cols),\n",
    "        ('nominal', cv_nominal_transformer, low_card_cols)\n",
    "    ], n_jobs=8)\n",
    "\n",
    "# 將前處理及學習模型定義為制式的 pipeline 工作流程\n",
    "cv_model = RandomForestRegressor(n_estimators=100, n_jobs=8)\n",
    "cv_pipe = Pipeline(steps=[('cv_preprocessor', cv_preprocessor), ('cv_model', cv_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § 使用 KFold\n",
    "\n",
    "使用 *n_splits* 參數指定要幾個 fold，`KFold.split()` 方法是生成函式，每一次的呼叫就返回該次 training 及 validation set 在原資料集中的列（row）序號，所以每個 fold 就是藉由這些序號分別指定當次要訓練或驗證的資料片段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #0:  MAE = 15561.177842465753\n",
      "Fold #1:  MAE = 17463.493732876712\n",
      "Fold #2:  MAE = 18616.774726027397\n",
      "Fold #3:  MAE = 21076.22719178082\n",
      "Fold #4:  MAE = 15776.444246575342\n",
      "Cross-Validation 平均 MAE = 17698.823547945205 ± 2028.2968816761897\n"
     ]
    }
   ],
   "source": [
    "# 使用 KFold 作交叉驗證\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 相同的工作流程套用到訓練集的學習，以及驗證集的預測\n",
    "MAEs = []\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for k, (train, valid) in enumerate(kfold.split(cv_X, y)):\n",
    "    cv_pipe.fit(cv_X.iloc[train,:], y.iloc[train])\n",
    "    predicts = cv_pipe.predict(cv_X.iloc[valid,:])\n",
    "    mae = mean_absolute_error(y.iloc[valid], predicts)\n",
    "    MAEs.append(mae)\n",
    "    print('Fold #{}:  MAE = {}'.format(k, mae))\n",
    "\n",
    "# Cross-Validation 平均的結果會比較接近真實狀況\n",
    "print('Cross-Validation 平均 MAE = {} ± {}'.format(np.mean(MAEs), np.std(MAEs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### § 應用範例 - 模型參數篩選\n",
    "\n",
    "機器學習裡有兩種形式的參數：\n",
    "1. 從訓練資料學習來的匹配資料特徵的參數，如多項式回歸模型中組成多項式的係數。\n",
    "2. 調整模型學習匹配特徵方式的參數，稱為**超參數（hyperparameters）**。\n",
    "\n",
    "k-Fold 交叉驗證常見用來重複多次執行，每一次都設定不同的模型超參數，用來比較不同超參數下的表現，以供最後模型選擇適合的參數組合（model selection）。 Scikit-learn 在 `model_selection` 模組下其實有提供方便的工具作參數的搜尋，不過要自己做也不是太難，以下示範一個簡單的範例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 cross_validate 作交叉驗證\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def get_scores(param_choice):\n",
    "    select_pipe = Pipeline(\n",
    "        steps=[\n",
    "            ('cv_preprocessor', cv_preprocessor),\n",
    "            ('model', RandomForestRegressor(n_estimators=param_choice, n_jobs=8))\n",
    "        ])\n",
    "    scoring = ['neg_mean_absolute_error', 'r2']\n",
    "    scores = cross_validate(select_pipe, cv_X, y,\n",
    "                            scoring=scoring,\n",
    "                            #cv=5,\n",
    "                            cv=KFold(n_splits=5, shuffle=True),\n",
    "                            n_jobs=8,\n",
    "                            return_train_score=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 estimators: 訓練平均 MAE = 6578.817715753426， 測試平均 MAE = 17918.745369863012\n",
      "75 estimators: 訓練平均 MAE = 6630.723630136987， 測試平均 MAE = 17238.8274977169\n",
      "100 estimators: 訓練平均 MAE = 6518.65927739726， 測試平均 MAE = 17341.84730136986\n",
      "125 estimators: 訓練平均 MAE = 6482.947234246576， 測試平均 MAE = 17579.77253150685\n",
      "150 estimators: 訓練平均 MAE = 6504.502076484017， 測試平均 MAE = 17604.170305936073\n",
      "175 estimators: 訓練平均 MAE = 6522.131869863014， 測試平均 MAE = 17388.067045009786\n",
      "200 estimators: 訓練平均 MAE = 6394.044496575342， 測試平均 MAE = 17360.680715753424\n",
      "225 estimators: 訓練平均 MAE = 6442.358764840183， 測試平均 MAE = 17500.129035007612\n",
      "250 estimators: 訓練平均 MAE = 6478.75538630137， 測試平均 MAE = 17218.51153150685\n",
      "275 estimators: 訓練平均 MAE = 6442.758410336239， 測試平均 MAE = 17344.805574097136\n",
      "300 estimators: 訓練平均 MAE = 6418.801578196347， 測試平均 MAE = 17551.230020547948\n",
      "325 estimators: 訓練平均 MAE = 6455.836890937829， 測試平均 MAE = 17324.005011591147\n",
      "350 estimators: 訓練平均 MAE = 6401.151367416829， 測試平均 MAE = 17267.01408806262\n",
      "375 estimators: 訓練平均 MAE = 6395.224507305936， 測試平均 MAE = 17373.303735159818\n",
      "400 estimators: 訓練平均 MAE = 6404.000945205478， 測試平均 MAE = 17580.888306506848\n",
      "425 estimators: 訓練平均 MAE = 6444.047885979049， 測試平均 MAE = 16843.931758259467\n",
      "450 estimators: 訓練平均 MAE = 6419.012782724504， 測試平均 MAE = 16943.514549467276\n",
      "475 estimators: 訓練平均 MAE = 6400.794680245133， 測試平均 MAE = 17348.450594087964\n",
      "500 estimators: 訓練平均 MAE = 6385.841866780822， 測試平均 MAE = 17580.33458082192\n",
      "最佳得分當次詳細結果： n_estimators = 425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.403233</td>\n",
       "      <td>0.901671</td>\n",
       "      <td>-16487.384722</td>\n",
       "      <td>-6357.981201</td>\n",
       "      <td>0.832716</td>\n",
       "      <td>0.981891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.585429</td>\n",
       "      <td>1.688227</td>\n",
       "      <td>-18196.118501</td>\n",
       "      <td>-6396.366684</td>\n",
       "      <td>0.896543</td>\n",
       "      <td>0.979023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.399350</td>\n",
       "      <td>0.905627</td>\n",
       "      <td>-15432.425552</td>\n",
       "      <td>-6642.964148</td>\n",
       "      <td>0.826979</td>\n",
       "      <td>0.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.689932</td>\n",
       "      <td>0.615045</td>\n",
       "      <td>-16458.519525</td>\n",
       "      <td>-6391.434502</td>\n",
       "      <td>0.901604</td>\n",
       "      <td>0.980346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.054987</td>\n",
       "      <td>0.438378</td>\n",
       "      <td>-17645.210492</td>\n",
       "      <td>-6431.492895</td>\n",
       "      <td>0.870990</td>\n",
       "      <td>0.979731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  6.403233    0.901671                 -16487.384722   \n",
       "1  5.585429    1.688227                 -18196.118501   \n",
       "2  6.399350    0.905627                 -15432.425552   \n",
       "3  6.689932    0.615045                 -16458.519525   \n",
       "4  7.054987    0.438378                 -17645.210492   \n",
       "\n",
       "   train_neg_mean_absolute_error   test_r2  train_r2  \n",
       "0                   -6357.981201  0.832716  0.981891  \n",
       "1                   -6396.366684  0.896543  0.979023  \n",
       "2                   -6642.964148  0.826979  0.981900  \n",
       "3                   -6391.434502  0.901604  0.980346  \n",
       "4                   -6431.492895  0.870990  0.979731  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用不同模型的參數執行多次交叉驗證，用來選擇較好的參數\n",
    "param_choices = list(range(50, 501, 25))\n",
    "results = {}\n",
    "test_mean_maes = {}\n",
    "train_mean_maes = {}\n",
    "for n in param_choices:\n",
    "    results[n] = get_scores(n)\n",
    "    # 記錄每次 k-Fold 的平均分數\n",
    "    test_mean_maes[n] = np.mean(np.fabs(results[n]['test_neg_mean_absolute_error'])) \n",
    "    train_mean_maes[n] = np.mean(np.fabs(results[n]['train_neg_mean_absolute_error'])) \n",
    "    print('{} estimators: 訓練平均 MAE = {}， 測試平均 MAE = {}'.format(n, train_mean_maes[n], test_mean_maes[n]))\n",
    "\n",
    "best_n_estimators = min(test_mean_maes, key=test_mean_maes.get)\n",
    "print('最佳得分當次詳細結果： n_estimators =', best_n_estimators)\n",
    "pd.DataFrame(results[best_n_estimators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x180f0419fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 畫出各參數表現的趨勢圖\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_mean_maes.keys(), train_mean_maes.values(), label='train')\n",
    "ax.plot(test_mean_maes.keys(), test_mean_maes.values(), label='test')\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('Average MAEs of k-Fold')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"references\"></a>\n",
    "\n",
    "## References:\n",
    "\n",
    "+ Dan Becker, *\"Intermediate Machine Learning\"*, Kaggle, 2019. [[link]](https://www.kaggle.com/learn/intermediate-machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
